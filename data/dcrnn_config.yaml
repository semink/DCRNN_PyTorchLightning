NONPARAMS:
  LOG:
    save_dir: experiments
    log_graph: True
    name: DCRNN-lightning

  SUMMARY:
    max_depth: 4

  TRAINER:
    gpus: [0] # set 0 (not [0]) if you don't have GPU
    gradient_clip_val: 5
    max_epochs: 60

  DATA:
    batch_size: 64
    seq_len: 12

  EARLY_STOPPING:
    patience: 20

  TEST:
    checkpoint:
      la: data/checkpoints/la.ckpt
      bay: data/checkpoints/bay.ckpt

HPARAMS:
  MODEL:
    max_diffusion_step: 2
    num_rnn_layers: 2
    rnn_units: 64
    input_dim: 2
    output_dim: 1
    horizon: 12

  METRIC:
    monitor_metric_name: 'validation/mae'
    training_metric_name: 'training/mae'

  TEACHER_FORCING:
    use_curriculum_learning: true
    cl_decay_steps: 2000

  OPTIMIZER:
    base_lr: 0.01
    eps: 1.0e-3
    milestones: [20, 30, 40, 50]
    gamma: 0.1